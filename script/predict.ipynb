{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-22T13:14:14.794546Z",
     "start_time": "2025-11-22T13:14:14.651104Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd \"/home/hew/python/contp\"\n",
    "%ls"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hew/python/contp\n",
      "\u001B[0m\u001B[01;34mckpt\u001B[0m/  \u001B[01;34mdataset\u001B[0m/  README.md  \u001B[01;34mtemp\u001B[0m/           \u001B[01;34mutils\u001B[0m/\r\n",
      "\u001B[01;34mdata\u001B[0m/  \u001B[01;34mmodel\u001B[0m/    \u001B[01;34mscript\u001B[0m/    Untitled.ipynb\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T13:14:19.848114Z",
     "start_time": "2025-11-22T13:14:15.304632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from model.ConTP_data_module import ConTPDataModule\n",
    "from model.ConTP_module import ConTPModule\n",
    "from utils.dataset import ProteinDataset\n",
    "from utils.lightning import LitModelInference"
   ],
   "id": "a655fad4152d6e6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= add root_path to sys.path =============================\n",
      "root_path: /home/hew/python/contp\n",
      "======================================================================================\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T13:14:20.026349Z",
     "start_time": "2025-11-22T13:14:20.000913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def compute_label_metrics(preds, labels):\n",
    "    # preds: [[3], [0]], labels: [[3, 1], [0]]\n",
    "    epoch_metrics = {}\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    mlb.fit(labels + preds)\n",
    "    y_true = mlb.transform(labels)\n",
    "    y_pred = mlb.transform(preds)\n",
    "\n",
    "    # weighted\n",
    "    weighted_precision, weighted_recall, weighted_f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='weighted', zero_division=0\n",
    "    )\n",
    "\n",
    "    # samples\n",
    "    samples_precision, samples_recall, samples_f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='samples', zero_division=0\n",
    "    )\n",
    "\n",
    "    # micro P/R/F1\n",
    "    micro_precision, micro_recall, micro_f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='micro', zero_division=0\n",
    "    )\n",
    "\n",
    "    # sample-wise exact accuracy (subset accuracy)\n",
    "    samples_acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # micro accuracy  ← 新增（展平成二分类）\n",
    "    micro_acc = accuracy_score(y_true.ravel(), y_pred.ravel())\n",
    "\n",
    "    # save\n",
    "    epoch_metrics['weighted_precision'] = weighted_precision\n",
    "    epoch_metrics['weighted_recall'] = weighted_recall\n",
    "    epoch_metrics['weighted_f1'] = weighted_f1\n",
    "\n",
    "    epoch_metrics['samples_precision'] = samples_precision\n",
    "    epoch_metrics['samples_recall'] = samples_recall\n",
    "    epoch_metrics['samples_f1'] = samples_f1\n",
    "    epoch_metrics['samples_acc'] = samples_acc\n",
    "\n",
    "    epoch_metrics['micro_precision'] = micro_precision\n",
    "    epoch_metrics['micro_recall'] = micro_recall\n",
    "    epoch_metrics['micro_f1'] = micro_f1\n",
    "    epoch_metrics['micro_acc'] = micro_acc\n",
    "    return epoch_metrics"
   ],
   "id": "c2759dd3d34c174d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T13:14:20.133292Z",
     "start_time": "2025-11-22T13:14:20.055427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def multi_label_from_distance(dist, threshold=0.03):\n",
    "    \"\"\"\n",
    "    根据距离矩阵 dist 计算多标签预测：\n",
    "    1) 对 -dist 做 softmax 得到概率\n",
    "    2) 对概率 > threshold 的类别作为预测标签\n",
    "    3) 若某样本无任何标签，则选择 Top-1\n",
    "    4) 返回每个样本的类别索引列表\n",
    "\n",
    "    参数:\n",
    "        dist: (N, C) torch.Tensor, 距离矩阵\n",
    "        threshold: float, 多标签概率阈值\n",
    "\n",
    "    返回:\n",
    "        final_preds: list[list[int]]\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) 对距离做 softmax → 概率\n",
    "    sorted_probs, sorted_indices = torch.sort(\n",
    "        torch.softmax(-dist, dim=1), descending=True\n",
    "    )\n",
    "    probs = sorted_probs\n",
    "    preds = sorted_indices\n",
    "\n",
    "    # 2) 得到 mask 与索引\n",
    "    mask = probs > threshold\n",
    "    indices = mask.nonzero(as_tuple=False)  # (K, 2)\n",
    "\n",
    "    N, C = probs.shape\n",
    "    multi_label_pred = [[] for _ in range(N)]\n",
    "\n",
    "    # 3) 阈值筛选\n",
    "    for sample_id, class_id in indices.tolist():\n",
    "        multi_label_pred[sample_id].append(class_id)\n",
    "\n",
    "    # 4) 若为空 → 选 top1\n",
    "    top1_ids = torch.argmax(probs, dim=1).tolist()\n",
    "    for i in range(N):\n",
    "        if len(multi_label_pred[i]) == 0:\n",
    "            multi_label_pred[i].append(top1_ids[i])\n",
    "\n",
    "    # 5) 根据 preds 中的真实 class_id 映射\n",
    "    final_preds = []\n",
    "    for i, idx_list in enumerate(multi_label_pred):\n",
    "        cls_list = [preds[i, idx].item() for idx in idx_list]\n",
    "        final_preds.append(cls_list)\n",
    "\n",
    "    return final_preds"
   ],
   "id": "2ee2e4978958ccd2",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T13:14:21.483302Z",
     "start_time": "2025-11-22T13:14:20.216875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# task = 'substrate_classification'\n",
    "task = 'tc_classification'\n",
    "if task == 'substrate_classification':\n",
    "    ckpt_path = '/home/hew/python/contp/ckpt/lightning_logs/substrate/checkpoints/last.ckpt'\n",
    "    temp_dir = './temp/inference_substrate/'\n",
    "    label_map = pd.read_csv('./data/substrate_mapping.csv')\n",
    "    select_cluster = label_map['id'].tolist()\n",
    "    label_key = 'substrate_ids'\n",
    "elif task == 'tc_classification':\n",
    "    ckpt_path = '/home/hew/python/contp/ckpt/lightning_logs/tc/checkpoints/last.ckpt'\n",
    "    temp_dir = './temp/inference_tc/'\n",
    "    label_map = pd.read_csv('./data/tc_mapping.csv')\n",
    "    select_cluster = label_map['id'].tolist()\n",
    "    label_key = 'label_id'\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "predictor = LitModelInference(ConTPModule, ConTPDataModule, ckpt_path)\n",
    "datamodule = predictor.pl_data_module\n",
    "# if task == 'substrate_classification':\n",
    "#     datamodule.dataset = ProteinDataset(name='TCDB_substrate', path='/home/hew/python/TPNet/dataset/TCDB_substrate')\n",
    "# elif task == 'tc_classification':\n",
    "#     datamodule.dataset = ProteinDataset(name='TCDB_tc', path='/home/hew/python/TPNet/dataset/TCDB_tc')\n",
    "# datamodule.dataframe = datamodule.dataset.metadata\n",
    "datamodule.dataset"
   ],
   "id": "3780edd601911027",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[loading checkpoint]: /home/hew/python/contp/ckpt/lightning_logs/tc/checkpoints/last.ckpt\n",
      "Loading metadata from /home/hew/python/contp/dataset/TCDB_tc/metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ProteinDataset[ TCDB_tc ], size: 99950, path: /home/hew/python/contp/dataset/TCDB_tc"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "datamodule.prepare_data()\n",
    "datamodule.setup('fit')\n",
    "datamodule.setup('test')"
   ],
   "id": "54ccbb3e78164bb1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T13:14:24.559258Z",
     "start_time": "2025-11-22T13:14:24.515035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cache_file = f'{temp_dir}/class_embeddings.pth'\n",
    "if os.path.exists(cache_file):\n",
    "    # if False:\n",
    "    class_embeddings = torch.load(cache_file)\n",
    "    idx2sample = pd.read_csv(f'{temp_dir}/idx2sample.csv')\n",
    "    idx2sample.set_index('sample_id', inplace=True)\n",
    "    select_cluster = np.load(f'{temp_dir}/select_cluster.npy')"
   ],
   "id": "55e4c3828d1e587",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3892771/415901130.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  class_embeddings = torch.load(cache_file)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_dataset = datamodule.test_dataset\n",
    "test_dataset_size = len(test_dataset)\n",
    "test_dataset"
   ],
   "id": "f8ad76185e3050c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from utils.wrapper.ESM import ESMWrapper",
   "id": "67b64523ec52dbb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query_seqs = test_dataset.metadata['sequence'].tolist()[:100]\n",
    "query_labels = test_dataset.metadata['substrate_ids'].map(eval).tolist()[:100]\n",
    "len(query_seqs), len(query_labels)"
   ],
   "id": "b1d2609935788004",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from utils.file import write_fasta\n",
    "\n",
    "write_fasta('./temp/example.fasta', query_seqs, [f'substrate_id: {y}' for y in query_labels])"
   ],
   "id": "e431c384297bf230",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = 'cpu'\n",
    "device = 'cuda:0'"
   ],
   "id": "637b06535f9a58b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "esm = ESMWrapper('./temp/esm/', device=device)\n",
    "esm.__init_submodule__()\n",
    "esm"
   ],
   "id": "4f43ddd180273777",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "batch_size = 20\n",
    "num_query = len(query_seqs)\n",
    "num_batches = (num_query // batch_size) + (0 if num_query % batch_size == 0 else 1)\n",
    "\n",
    "query_esm = []\n",
    "for i in tqdm(range(num_batches), desc='Computing ESM Embeddings'):\n",
    "    batch_seqs = query_seqs[i * batch_size: (i + 1) * batch_size]\n",
    "    batch_embed = esm.forward(batch_seqs)['mean_representations']\n",
    "    query_esm.append(batch_embed)\n",
    "\n",
    "query_esm = torch.concat(query_esm, dim=0)\n",
    "query_esm.shape"
   ],
   "id": "3189983968366c68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = 'cuda:0'\n",
    "query_X = predictor.ckpt_model.model.forward(query_esm.to(device))\n",
    "query_X.shape"
   ],
   "id": "9774badbb9ef895d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query_X = query_X\n",
    "query_label = query_labels\n",
    "\n",
    "train_C = class_embeddings\n",
    "raw_pred, dist = predictor.ckpt_model.model.find_nearest_cluster(query_X, train_C, return_dist=True)\n",
    "pred = np.array([select_cluster[i] for i in raw_pred])\n",
    "pred = [[y] for y in pred]\n",
    "compute_label_metrics(pred, query_label)"
   ],
   "id": "ef76b35aec79ade6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prob = torch.softmax(-dist, dim=1)\n",
    "prob[0]"
   ],
   "id": "f1a1239deee6593e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "result = torch.sort(prob, descending=True)\n",
    "probs = result[0]\n",
    "preds = result[1]\n",
    "probs[0], preds[0]"
   ],
   "id": "a11deda16fe16384",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if task == 'substrate_classification':\n",
    "    threshold = 0.034  # determined in the training set\n",
    "    final_preds = multi_label_from_distance(dist, threshold=threshold)\n",
    "    metrics = compute_label_metrics(final_preds, query_label)\n",
    "else:\n",
    "    final_preds = pred\n",
    "    metrics = compute_label_metrics(pred, query_label)\n",
    "metrics"
   ],
   "id": "e88b44d33740d232",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "final_preds",
   "id": "1a17cb6b54d7d80c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1bc7ab1e7affe805",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6d03618a8260a0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T13:14:33.013571Z",
     "start_time": "2025-11-22T13:14:32.946766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils.file import read_fasta\n",
    "from utils.wrapper.ESM import ESMWrapper\n",
    "\n",
    "query_seqs, query_labels = read_fasta('./temp/example.fasta')\n",
    "query_labels = [eval(y.split('substrate_id: ')[-1]) for y in query_labels]\n",
    "len(query_seqs), len(query_labels)"
   ],
   "id": "2779079d4675d9c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T13:14:33.774029Z",
     "start_time": "2025-11-22T13:14:33.733979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# device = 'cpu'\n",
    "device = 'cuda:0'"
   ],
   "id": "c98bcc914baee049",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T13:14:47.493477Z",
     "start_time": "2025-11-22T13:14:34.540464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "esm = ESMWrapper('./temp/esm/', device=device)\n",
    "esm.__init_submodule__()\n",
    "esm"
   ],
   "id": "691c0987fee6e859",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ESM] ESM model initializing...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ESMWrapper(path=/home/hew/python/contp/temp/esm/esm2_t33_650M_UR50D)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T13:15:12.145818Z",
     "start_time": "2025-11-22T13:14:47.547771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 20\n",
    "num_query = len(query_seqs)\n",
    "num_batches = (num_query // batch_size) + (0 if num_query % batch_size == 0 else 1)\n",
    "\n",
    "query_esm = []\n",
    "for i in tqdm(range(num_batches), desc='Computing ESM Embeddings'):\n",
    "    batch_seqs = query_seqs[i * batch_size: (i + 1) * batch_size]\n",
    "    batch_embed = esm.forward(batch_seqs)['mean_representations']\n",
    "    query_esm.append(batch_embed)\n",
    "\n",
    "query_esm = torch.concat(query_esm, dim=0)\n",
    "query_esm.shape"
   ],
   "id": "bb84f1770a3bdd53",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computing ESM Embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1e0668c3bb54e3c8ec4f7817ea73998"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1280])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T13:15:12.266867Z",
     "start_time": "2025-11-22T13:15:12.202248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = 'cuda:0'\n",
    "query_X = predictor.ckpt_model.model.forward(query_esm.to(device))\n",
    "query_X.shape"
   ],
   "id": "cfa52ecae9a9162d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 320])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T13:15:12.424565Z",
     "start_time": "2025-11-22T13:15:12.302266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_X = query_X\n",
    "query_label = query_labels\n",
    "\n",
    "train_C = class_embeddings\n",
    "raw_pred, dist = predictor.ckpt_model.model.find_nearest_cluster(query_X, train_C, return_dist=True)"
   ],
   "id": "49d1bac83ecc9da4",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T13:18:19.216222Z",
     "start_time": "2025-11-22T13:18:19.165940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if task == 'substrate_classification':\n",
    "    threshold = 0.034  # determined in the training set\n",
    "    preds = multi_label_from_distance(dist, threshold=threshold)\n",
    "\n",
    "    final_pred = []\n",
    "    for pred_list in preds:\n",
    "        pred_labels = [label_map.loc[pred_y, 'substrate'] for pred_y in pred_list]\n",
    "        final_pred.append(pred_labels)\n",
    "else:\n",
    "    preds = np.array([select_cluster[i] for i in raw_pred])\n",
    "    final_pred = [label_map.loc[pred, 'tcid'] for pred in preds]\n",
    "\n",
    "pred_df = pd.DataFrame(final_pred)\n",
    "if task == 'substrate_classification':\n",
    "    pred_df.columns = [f'substrate_top{col + 1}' for col in pred_df.columns.tolist()]\n",
    "else:\n",
    "    pred_df.columns = ['tcid']\n",
    "pred_df.to_csv('./temp/prediction.csv', index=False)\n",
    "pred_df"
   ],
   "id": "e72cb37b6b41da35",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        tcid\n",
       "0   1.A.1.11\n",
       "1   1.A.1.11\n",
       "2   1.A.1.13\n",
       "3   1.A.1.13\n",
       "4   1.A.1.13\n",
       "..       ...\n",
       "95  1.A.26.2\n",
       "96  1.A.30.1\n",
       "97  1.A.30.1\n",
       "98  1.A.30.1\n",
       "99  1.A.30.2\n",
       "\n",
       "[100 rows x 1 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tcid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.A.1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.A.1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.A.1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.A.1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.A.1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.A.26.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1.A.30.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1.A.30.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.A.30.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.A.30.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "de29d32685ddcc5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:GPTDesign]",
   "language": "python",
   "name": "conda-env-GPTDesign-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
