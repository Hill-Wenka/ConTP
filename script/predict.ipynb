{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-25T19:18:42.851021Z",
     "start_time": "2025-11-25T19:18:42.701828Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd \"/home/hew/python/contp\"\n",
    "%ls"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hew/python/contp\n",
      "\u001B[0m\u001B[01;34mckpt\u001B[0m/  \u001B[01;34mdataset\u001B[0m/      \u001B[01;31mdataset.zip\u001B[0m  \u001B[01;34mmodel\u001B[0m/     \u001B[01;34mscript\u001B[0m/  \u001B[01;34mutils\u001B[0m/\r\n",
      "\u001B[01;34mdata\u001B[0m/  \u001B[01;34mdataset_bak\u001B[0m/  \u001B[01;34mesm3_pred\u001B[0m/   README.md  \u001B[01;34mtemp\u001B[0m/\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:18:47.950182Z",
     "start_time": "2025-11-25T19:18:43.290806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from model.ConTP_data_module import ConTPDataModule\n",
    "from model.ConTP_module import ConTPModule\n",
    "from utils.dataset import ProteinDataset\n",
    "from utils.lightning import LitModelInference"
   ],
   "id": "a655fad4152d6e6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= add root_path to sys.path =============================\n",
      "root_path: /home/hew/python/contp\n",
      "======================================================================================\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:18:48.187794Z",
     "start_time": "2025-11-25T19:18:48.158702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def compute_label_metrics(preds, labels):\n",
    "    # preds: [[3], [0]], labels: [[3, 1], [0]]\n",
    "    epoch_metrics = {}\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    mlb.fit(labels + preds)\n",
    "    y_true = mlb.transform(labels)\n",
    "    y_pred = mlb.transform(preds)\n",
    "\n",
    "    # weighted\n",
    "    weighted_precision, weighted_recall, weighted_f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='weighted', zero_division=0\n",
    "    )\n",
    "\n",
    "    # samples\n",
    "    samples_precision, samples_recall, samples_f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='samples', zero_division=0\n",
    "    )\n",
    "\n",
    "    # micro P/R/F1\n",
    "    micro_precision, micro_recall, micro_f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='micro', zero_division=0\n",
    "    )\n",
    "\n",
    "    # sample-wise exact accuracy (subset accuracy)\n",
    "    samples_acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # micro accuracy  ← 新增（展平成二分类）\n",
    "    micro_acc = accuracy_score(y_true.ravel(), y_pred.ravel())\n",
    "\n",
    "    # save\n",
    "    epoch_metrics['weighted_precision'] = weighted_precision\n",
    "    epoch_metrics['weighted_recall'] = weighted_recall\n",
    "    epoch_metrics['weighted_f1'] = weighted_f1\n",
    "\n",
    "    epoch_metrics['samples_precision'] = samples_precision\n",
    "    epoch_metrics['samples_recall'] = samples_recall\n",
    "    epoch_metrics['samples_f1'] = samples_f1\n",
    "    epoch_metrics['samples_acc'] = samples_acc\n",
    "\n",
    "    epoch_metrics['micro_precision'] = micro_precision\n",
    "    epoch_metrics['micro_recall'] = micro_recall\n",
    "    epoch_metrics['micro_f1'] = micro_f1\n",
    "    epoch_metrics['micro_acc'] = micro_acc\n",
    "    return epoch_metrics"
   ],
   "id": "c2759dd3d34c174d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:18:48.294596Z",
     "start_time": "2025-11-25T19:18:48.213777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def multi_label_from_distance(dist, threshold=0.03):\n",
    "    \"\"\"\n",
    "    根据距离矩阵 dist 计算多标签预测：\n",
    "    1) 对 -dist 做 softmax 得到概率\n",
    "    2) 对概率 > threshold 的类别作为预测标签\n",
    "    3) 若某样本无任何标签，则选择 Top-1\n",
    "    4) 返回每个样本的类别索引列表\n",
    "\n",
    "    参数:\n",
    "        dist: (N, C) torch.Tensor, 距离矩阵\n",
    "        threshold: float, 多标签概率阈值\n",
    "\n",
    "    返回:\n",
    "        final_preds: list[list[int]]\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) 对距离做 softmax → 概率\n",
    "    sorted_probs, sorted_indices = torch.sort(\n",
    "        torch.softmax(-dist, dim=1), descending=True\n",
    "    )\n",
    "    probs = sorted_probs\n",
    "    preds = sorted_indices\n",
    "\n",
    "    # 2) 得到 mask 与索引\n",
    "    mask = probs > threshold\n",
    "    indices = mask.nonzero(as_tuple=False)  # (K, 2)\n",
    "\n",
    "    N, C = probs.shape\n",
    "    multi_label_pred = [[] for _ in range(N)]\n",
    "\n",
    "    # 3) 阈值筛选\n",
    "    for sample_id, class_id in indices.tolist():\n",
    "        multi_label_pred[sample_id].append(class_id)\n",
    "\n",
    "    # 4) 若为空 → 选 top1\n",
    "    top1_ids = torch.argmax(probs, dim=1).tolist()\n",
    "    for i in range(N):\n",
    "        if len(multi_label_pred[i]) == 0:\n",
    "            multi_label_pred[i].append(top1_ids[i])\n",
    "\n",
    "    # 5) 根据 preds 中的真实 class_id 映射\n",
    "    final_preds = []\n",
    "    for i, idx_list in enumerate(multi_label_pred):\n",
    "        cls_list = [preds[i, idx].item() for idx in idx_list]\n",
    "        final_preds.append(cls_list)\n",
    "\n",
    "    return final_preds"
   ],
   "id": "2ee2e4978958ccd2",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:18:49.673Z",
     "start_time": "2025-11-25T19:18:48.325291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# task = 'substrate_classification'\n",
    "task = 'tc_classification'\n",
    "if task == 'substrate_classification':\n",
    "    ckpt_path = '/home/hew/python/contp/ckpt/lightning_logs/substrate/checkpoints/last.ckpt'\n",
    "    temp_dir = './temp/inference_substrate/'\n",
    "    label_map = pd.read_csv('./data/substrate_mapping.csv')\n",
    "    select_cluster = label_map['id'].tolist()\n",
    "    label_key = 'substrate_ids'\n",
    "elif task == 'tc_classification':\n",
    "    ckpt_path = '/home/hew/python/contp/ckpt/lightning_logs/tc/checkpoints/last.ckpt'\n",
    "    temp_dir = './temp/inference_tc/'\n",
    "    label_map = pd.read_csv('./data/tc_mapping.csv')\n",
    "    select_cluster = label_map['id'].tolist()\n",
    "    label_key = 'label_id'\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "predictor = LitModelInference(ConTPModule, ConTPDataModule, ckpt_path)\n",
    "datamodule = predictor.pl_data_module\n",
    "# if task == 'substrate_classification':\n",
    "#     datamodule.dataset = ProteinDataset(name='TCDB_substrate', path='/home/hew/python/TPNet/dataset/TCDB_substrate')\n",
    "# elif task == 'tc_classification':\n",
    "#     datamodule.dataset = ProteinDataset(name='TCDB_tc', path='/home/hew/python/TPNet/dataset/TCDB_tc')\n",
    "# datamodule.dataframe = datamodule.dataset.metadata\n",
    "datamodule.dataset"
   ],
   "id": "3780edd601911027",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[loading checkpoint]: /home/hew/python/contp/ckpt/lightning_logs/tc/checkpoints/last.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ProteinDataset[ TCDB_tc ], size: 99950, path: /home/hew/python/contp/dataset/TCDB_tc"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:18:55.797474Z",
     "start_time": "2025-11-25T19:18:49.715021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "datamodule.prepare_data()\n",
    "datamodule.setup('fit')\n",
    "datamodule.setup('test')"
   ],
   "id": "54ccbb3e78164bb1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use the original split of the dataset\n",
      "[prepare_data] max_len: 2000, subset_ratio: 1, number: 83266\n",
      "============================== Setup [fit] Start ==============================\n",
      "[self.train_dataset] 58286\n",
      "[self.val_dataset] 24980\n",
      "============================== Setup [fit] End ==============================\n",
      "============================== Setup [test] Start ==============================\n",
      "[self.test_dataset] 24980\n",
      "============================== Setup [test] End ==============================\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:18:55.884675Z",
     "start_time": "2025-11-25T19:18:55.848450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cache_file = f'{temp_dir}/class_embeddings.pth'\n",
    "if os.path.exists(cache_file):\n",
    "    # if False:\n",
    "    class_embeddings = torch.load(cache_file)\n",
    "    idx2sample = pd.read_csv(f'{temp_dir}/idx2sample.csv')\n",
    "    idx2sample.set_index('sample_id', inplace=True)\n",
    "    select_cluster = np.load(f'{temp_dir}/select_cluster.npy')"
   ],
   "id": "55e4c3828d1e587",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3064784/415901130.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  class_embeddings = torch.load(cache_file)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:18:55.956594Z",
     "start_time": "2025-11-25T19:18:55.916525Z"
    }
   },
   "cell_type": "code",
   "source": "select_cluster",
   "id": "574766ecfca519f4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    2,    3, ..., 1348, 1349, 1350])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:18:55.994786Z",
     "start_time": "2025-11-25T19:18:55.991985Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a456ef18f1534312",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:18:56.049134Z",
     "start_time": "2025-11-25T19:18:56.021500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_dataset = datamodule.test_dataset\n",
    "test_dataset_size = len(test_dataset)\n",
    "test_dataset"
   ],
   "id": "f8ad76185e3050c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProteinDataset[ test_dataset ], size: 24980, path: /home/hew/python/contp/dataset/TCDB_tc"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:18:56.177752Z",
     "start_time": "2025-11-25T19:18:56.067860Z"
    }
   },
   "cell_type": "code",
   "source": "from utils.wrapper.ESM import ESMWrapper",
   "id": "67b64523ec52dbb9",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:18:56.269712Z",
     "start_time": "2025-11-25T19:18:56.233132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_seqs = test_dataset.metadata['sequence'].tolist()[:100]\n",
    "# query_labels = test_dataset.metadata['substrate_ids'].map(eval).tolist()[:100]\n",
    "query_labels = test_dataset.metadata['label_id'].tolist()[:100]\n",
    "query_labels = [[y] for y in query_labels]\n",
    "len(query_seqs), len(query_labels)"
   ],
   "id": "b1d2609935788004",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:18:56.390717Z",
     "start_time": "2025-11-25T19:18:56.282420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils.file import write_fasta\n",
    "\n",
    "write_fasta('./temp/example.fasta', query_seqs, [f'substrate_id: {y}' for y in query_labels])"
   ],
   "id": "e431c384297bf230",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:18:56.471386Z",
     "start_time": "2025-11-25T19:18:56.436217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = 'cpu'\n",
    "device = 'cuda:0'"
   ],
   "id": "637b06535f9a58b",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:19:09.604975Z",
     "start_time": "2025-11-25T19:18:56.506308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "esm = ESMWrapper('./temp/esm/', device=device)\n",
    "esm.__init_submodule__()\n",
    "esm"
   ],
   "id": "4f43ddd180273777",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ESM] ESM model initializing...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ESMWrapper(path=/home/hew/python/contp/temp/esm/esm2_t33_650M_UR50D)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:19:32.828192Z",
     "start_time": "2025-11-25T19:19:09.650012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 20\n",
    "num_query = len(query_seqs)\n",
    "num_batches = (num_query // batch_size) + (0 if num_query % batch_size == 0 else 1)\n",
    "\n",
    "query_esm = []\n",
    "for i in tqdm(range(num_batches), desc='Computing ESM Embeddings'):\n",
    "    batch_seqs = query_seqs[i * batch_size: (i + 1) * batch_size]\n",
    "    batch_embed = esm.forward(batch_seqs)['mean_representations']\n",
    "    query_esm.append(batch_embed)\n",
    "\n",
    "query_esm = torch.concat(query_esm, dim=0)\n",
    "query_esm.shape"
   ],
   "id": "3189983968366c68",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computing ESM Embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bd75bceae9894834ab86506d9c3ad405"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1280])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:19:32.971509Z",
     "start_time": "2025-11-25T19:19:32.862731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = 'cuda:0'\n",
    "query_X = predictor.ckpt_model.model.forward(query_esm.to(device))\n",
    "query_X.shape"
   ],
   "id": "9774badbb9ef895d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 320])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:19:33.213919Z",
     "start_time": "2025-11-25T19:19:33.066901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_X = query_X\n",
    "query_label = query_labels\n",
    "\n",
    "train_C = class_embeddings\n",
    "raw_pred, dist = predictor.ckpt_model.model.find_nearest_cluster(query_X, train_C, return_dist=True)\n",
    "pred = np.array([select_cluster[i] for i in raw_pred])\n",
    "pred = [[y] for y in pred]\n",
    "compute_label_metrics(pred, query_label)"
   ],
   "id": "ef76b35aec79ade6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weighted_precision': 0.955,\n",
       " 'weighted_recall': 0.92,\n",
       " 'weighted_f1': 0.9318217338217337,\n",
       " 'samples_precision': 0.92,\n",
       " 'samples_recall': 0.92,\n",
       " 'samples_f1': 0.92,\n",
       " 'samples_acc': 0.92,\n",
       " 'micro_precision': 0.92,\n",
       " 'micro_recall': 0.92,\n",
       " 'micro_f1': 0.92,\n",
       " 'micro_acc': 0.9956756756756757}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:19:33.417689Z",
     "start_time": "2025-11-25T19:19:33.269638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prob = torch.softmax(-dist, dim=1)\n",
    "prob[0]"
   ],
   "id": "f1a1239deee6593e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0033, 0.0010, 0.0013,  ..., 0.0012, 0.0007, 0.0010], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:19:33.730652Z",
     "start_time": "2025-11-25T19:19:33.466445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = torch.sort(prob, descending=True)\n",
    "probs = result[0]\n",
    "preds = result[1]\n",
    "probs[0], preds[0]"
   ],
   "id": "a11deda16fe16384",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0033, 0.0016, 0.0015,  ..., 0.0007, 0.0007, 0.0007], device='cuda:0',\n",
       "        grad_fn=<SelectBackward0>),\n",
       " tensor([  0,  71,   3,  ..., 749, 949, 737], device='cuda:0'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:19:33.819550Z",
     "start_time": "2025-11-25T19:19:33.775627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if task == 'substrate_classification':\n",
    "    threshold = 0.034  # determined in the training set\n",
    "    final_preds = multi_label_from_distance(dist, threshold=threshold)\n",
    "    metrics = compute_label_metrics(final_preds, query_label)\n",
    "else:\n",
    "    final_preds = pred\n",
    "    metrics = compute_label_metrics(pred, query_label)\n",
    "metrics"
   ],
   "id": "e88b44d33740d232",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weighted_precision': 0.955,\n",
       " 'weighted_recall': 0.92,\n",
       " 'weighted_f1': 0.9318217338217337,\n",
       " 'samples_precision': 0.92,\n",
       " 'samples_recall': 0.92,\n",
       " 'samples_f1': 0.92,\n",
       " 'samples_acc': 0.92,\n",
       " 'micro_precision': 0.92,\n",
       " 'micro_recall': 0.92,\n",
       " 'micro_f1': 0.92,\n",
       " 'micro_acc': 0.9956756756756757}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:19:33.904564Z",
     "start_time": "2025-11-25T19:19:33.870321Z"
    }
   },
   "cell_type": "code",
   "source": "final_preds",
   "id": "1a17cb6b54d7d80c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [2],\n",
       " [2],\n",
       " [3],\n",
       " [3],\n",
       " [4],\n",
       " [4],\n",
       " [10],\n",
       " [5],\n",
       " [5],\n",
       " [5],\n",
       " [5],\n",
       " [6],\n",
       " [6],\n",
       " [6],\n",
       " [7],\n",
       " [7],\n",
       " [7],\n",
       " [7],\n",
       " [7],\n",
       " [7],\n",
       " [7],\n",
       " [7],\n",
       " [7],\n",
       " [7],\n",
       " [7],\n",
       " [8],\n",
       " [8],\n",
       " [9],\n",
       " [10],\n",
       " [10],\n",
       " [10],\n",
       " [12],\n",
       " [12],\n",
       " [13],\n",
       " [13],\n",
       " [13],\n",
       " [13],\n",
       " [13],\n",
       " [13],\n",
       " [13],\n",
       " [13],\n",
       " [13],\n",
       " [14],\n",
       " [14],\n",
       " [15],\n",
       " [16],\n",
       " [16],\n",
       " [16],\n",
       " [17],\n",
       " [17],\n",
       " [17],\n",
       " [20],\n",
       " [777],\n",
       " [22],\n",
       " [22],\n",
       " [23],\n",
       " [23],\n",
       " [23],\n",
       " [24],\n",
       " [24],\n",
       " [24],\n",
       " [24],\n",
       " [24],\n",
       " [23],\n",
       " [24],\n",
       " [25],\n",
       " [25],\n",
       " [26],\n",
       " [26],\n",
       " [28],\n",
       " [28],\n",
       " [28],\n",
       " [28],\n",
       " [29],\n",
       " [29],\n",
       " [29],\n",
       " [33],\n",
       " [37],\n",
       " [37],\n",
       " [416],\n",
       " [38],\n",
       " [878],\n",
       " [797],\n",
       " [878],\n",
       " [41],\n",
       " [41],\n",
       " [43],\n",
       " [43],\n",
       " [43],\n",
       " [44],\n",
       " [44],\n",
       " [44],\n",
       " [44],\n",
       " [1337],\n",
       " [45]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:19:34.002214Z",
     "start_time": "2025-11-25T19:19:33.959410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if task == 'substrate_classification':\n",
    "    threshold = 0.034  # determined in the training set\n",
    "    preds = multi_label_from_distance(dist, threshold=threshold)\n",
    "\n",
    "    final_pred = []\n",
    "    for pred_list in preds:\n",
    "        pred_labels = [label_map.loc[pred_y, 'substrate'] for pred_y in pred_list]\n",
    "        final_pred.append(pred_labels)\n",
    "else:\n",
    "    preds = np.array([select_cluster[i] for i in raw_pred])\n",
    "    final_pred = [label_map.loc[pred, 'tcid'] for pred in preds]\n",
    "\n",
    "pred_df = pd.DataFrame(final_pred)\n",
    "if task == 'substrate_classification':\n",
    "    pred_df.columns = [f'substrate_top{col + 1}' for col in pred_df.columns.tolist()]\n",
    "else:\n",
    "    pred_df.columns = ['tcid']\n",
    "pred_df.to_csv('./temp/prediction.csv', index=False)\n",
    "pred_df"
   ],
   "id": "a672cda22ae1efae",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         tcid\n",
       "0    1.A.1.11\n",
       "1    1.A.1.11\n",
       "2    1.A.1.11\n",
       "3    1.A.1.11\n",
       "4    1.A.1.11\n",
       "..        ...\n",
       "95  1.A.130.1\n",
       "96  1.A.130.1\n",
       "97  1.A.130.1\n",
       "98   9.B.65.1\n",
       "99  1.A.131.1\n",
       "\n",
       "[100 rows x 1 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tcid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.A.1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.A.1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.A.1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.A.1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.A.1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.A.130.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1.A.130.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1.A.130.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>9.B.65.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.A.131.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:19:34.106385Z",
     "start_time": "2025-11-25T19:19:34.104196Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "1bc7ab1e7affe805",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:19:34.147734Z",
     "start_time": "2025-11-25T19:19:34.144790Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "751fb300744e201",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:19:34.217137Z",
     "start_time": "2025-11-25T19:19:34.214453Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "dfd98791f2c78505",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:19:34.273093Z",
     "start_time": "2025-11-25T19:19:34.270087Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "6d03618a8260a0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:19:34.387041Z",
     "start_time": "2025-11-25T19:19:34.349538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils.file import read_fasta\n",
    "from utils.wrapper.ESM import ESMWrapper\n",
    "\n",
    "query_seqs, query_labels = read_fasta('./temp/example.fasta')\n",
    "query_labels = [eval(y.split('substrate_id: ')[-1]) for y in query_labels]\n",
    "len(query_seqs), len(query_labels)"
   ],
   "id": "2779079d4675d9c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:19:34.459098Z",
     "start_time": "2025-11-25T19:19:34.429392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# device = 'cpu'\n",
    "device = 'cuda:0'"
   ],
   "id": "c98bcc914baee049",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:19:45.918794Z",
     "start_time": "2025-11-25T19:19:34.493180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "esm = ESMWrapper('./temp/esm/', device=device)\n",
    "esm.__init_submodule__()\n",
    "esm"
   ],
   "id": "691c0987fee6e859",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ESM] ESM model initializing...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ESMWrapper(path=/home/hew/python/contp/temp/esm/esm2_t33_650M_UR50D)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:20:08.043640Z",
     "start_time": "2025-11-25T19:19:45.977106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 20\n",
    "num_query = len(query_seqs)\n",
    "num_batches = (num_query // batch_size) + (0 if num_query % batch_size == 0 else 1)\n",
    "\n",
    "query_esm = []\n",
    "for i in tqdm(range(num_batches), desc='Computing ESM Embeddings'):\n",
    "    batch_seqs = query_seqs[i * batch_size: (i + 1) * batch_size]\n",
    "    batch_embed = esm.forward(batch_seqs)['mean_representations']\n",
    "    query_esm.append(batch_embed)\n",
    "\n",
    "query_esm = torch.concat(query_esm, dim=0)\n",
    "query_esm.shape"
   ],
   "id": "bb84f1770a3bdd53",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computing ESM Embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f2f351e2dc5d43b79461202fa548867e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1280])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:20:08.110194Z",
     "start_time": "2025-11-25T19:20:08.082194Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = 'cuda:0'\n",
    "query_X = predictor.ckpt_model.model.forward(query_esm.to(device))\n",
    "query_X.shape"
   ],
   "id": "cfa52ecae9a9162d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 320])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:20:08.186313Z",
     "start_time": "2025-11-25T19:20:08.150046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_X = query_X\n",
    "query_label = query_labels\n",
    "\n",
    "train_C = class_embeddings\n",
    "raw_pred, dist = predictor.ckpt_model.model.find_nearest_cluster(query_X, train_C, return_dist=True)"
   ],
   "id": "49d1bac83ecc9da4",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:20:08.273988Z",
     "start_time": "2025-11-25T19:20:08.213748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if task == 'substrate_classification':\n",
    "    threshold = 0.034  # determined in the training set\n",
    "    preds = multi_label_from_distance(dist, threshold=threshold)\n",
    "\n",
    "    final_pred = []\n",
    "    for pred_list in preds:\n",
    "        pred_labels = [label_map.loc[pred_y, 'substrate'] for pred_y in pred_list]\n",
    "        final_pred.append(pred_labels)\n",
    "else:\n",
    "    preds = np.array([select_cluster[i] for i in raw_pred])\n",
    "    final_pred = [label_map.loc[pred, 'tcid'] for pred in preds]\n",
    "\n",
    "pred_df = pd.DataFrame(final_pred)\n",
    "if task == 'substrate_classification':\n",
    "    pred_df.columns = [f'substrate_top{col + 1}' for col in pred_df.columns.tolist()]\n",
    "else:\n",
    "    pred_df.columns = ['tcid']\n",
    "pred_df.to_csv('./temp/prediction.csv', index=False)\n",
    "pred_df"
   ],
   "id": "e72cb37b6b41da35",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         tcid\n",
       "0    1.A.1.11\n",
       "1    1.A.1.11\n",
       "2    1.A.1.11\n",
       "3    1.A.1.11\n",
       "4    1.A.1.11\n",
       "..        ...\n",
       "95  1.A.130.1\n",
       "96  1.A.130.1\n",
       "97  1.A.130.1\n",
       "98   9.B.65.1\n",
       "99  1.A.131.1\n",
       "\n",
       "[100 rows x 1 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tcid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.A.1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.A.1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.A.1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.A.1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.A.1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.A.130.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1.A.130.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1.A.130.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>9.B.65.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.A.131.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T19:20:08.360332Z",
     "start_time": "2025-11-25T19:20:08.357470Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "de29d32685ddcc5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:GPTDesign]",
   "language": "python",
   "name": "conda-env-GPTDesign-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
