{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-22T14:09:23.708240Z",
     "start_time": "2025-11-22T14:09:23.567382Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd \"/home/hew/python/contp\"\n",
    "%ls"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hew/python/contp\n",
      "\u001B[0m\u001B[01;34mckpt\u001B[0m/     \u001B[01;34mdataset_bak\u001B[0m/         \u001B[01;34mmodel\u001B[0m/     \u001B[01;34mtemp\u001B[0m/           wget-log\r\n",
      "\u001B[01;34mdata\u001B[0m/     \u001B[01;31mdataset.zip\u001B[0m          README.md  Untitled.ipynb\r\n",
      "\u001B[01;34mdataset\u001B[0m/  download_dataset.sh  \u001B[01;34mscript\u001B[0m/    \u001B[01;34mutils\u001B[0m/\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hew/anaconda3/envs/contp/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:09:28.741457Z",
     "start_time": "2025-11-22T14:09:23.955191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from model.ConTP_data_module import ConTPDataModule\n",
    "from model.ConTP_module import ConTPModule\n",
    "from utils.dataset import ProteinDataset\n",
    "from utils.lightning import LitModelInference"
   ],
   "id": "32b1d3a7e7b1e022",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= add root_path to sys.path =============================\n",
      "root_path: /home/hew/python/contp\n",
      "======================================================================================\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:09:28.901267Z",
     "start_time": "2025-11-22T14:09:28.865384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def compute_label_metrics(preds, labels):\n",
    "    # preds: [[3], [0]], labels: [[3, 1], [0]]\n",
    "    epoch_metrics = {}\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    mlb.fit(labels + preds)\n",
    "    y_true = mlb.transform(labels)\n",
    "    y_pred = mlb.transform(preds)\n",
    "\n",
    "    # weighted\n",
    "    weighted_precision, weighted_recall, weighted_f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='weighted', zero_division=0\n",
    "    )\n",
    "\n",
    "    # samples\n",
    "    samples_precision, samples_recall, samples_f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='samples', zero_division=0\n",
    "    )\n",
    "\n",
    "    # micro P/R/F1\n",
    "    micro_precision, micro_recall, micro_f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='micro', zero_division=0\n",
    "    )\n",
    "\n",
    "    # sample-wise exact accuracy (subset accuracy)\n",
    "    samples_acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # micro accuracy  ← 新增（展平成二分类）\n",
    "    micro_acc = accuracy_score(y_true.ravel(), y_pred.ravel())\n",
    "\n",
    "    # save\n",
    "    epoch_metrics['weighted_precision'] = weighted_precision\n",
    "    epoch_metrics['weighted_recall'] = weighted_recall\n",
    "    epoch_metrics['weighted_f1'] = weighted_f1\n",
    "\n",
    "    epoch_metrics['samples_precision'] = samples_precision\n",
    "    epoch_metrics['samples_recall'] = samples_recall\n",
    "    epoch_metrics['samples_f1'] = samples_f1\n",
    "    epoch_metrics['samples_acc'] = samples_acc\n",
    "\n",
    "    epoch_metrics['micro_precision'] = micro_precision\n",
    "    epoch_metrics['micro_recall'] = micro_recall\n",
    "    epoch_metrics['micro_f1'] = micro_f1\n",
    "    epoch_metrics['micro_acc'] = micro_acc\n",
    "    return epoch_metrics"
   ],
   "id": "96d135e0107c83ad",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:09:29.016377Z",
     "start_time": "2025-11-22T14:09:28.937418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def multi_label_from_distance(dist, threshold=0.035):\n",
    "    \"\"\"\n",
    "    根据距离矩阵 dist 计算多标签预测：\n",
    "    1) 对 -dist 做 softmax 得到概率\n",
    "    2) 对概率 > threshold 的类别作为预测标签\n",
    "    3) 若某样本无任何标签，则选择 Top-1\n",
    "    4) 返回每个样本的类别索引列表\n",
    "\n",
    "    参数:\n",
    "        dist: (N, C) torch.Tensor, 距离矩阵\n",
    "        threshold: float, 多标签概率阈值\n",
    "\n",
    "    返回:\n",
    "        final_preds: list[list[int]]\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) 对距离做 softmax → 概率\n",
    "    sorted_probs, sorted_indices = torch.sort(\n",
    "        torch.softmax(-dist, dim=1), descending=True\n",
    "    )\n",
    "    probs = sorted_probs\n",
    "    preds = sorted_indices\n",
    "\n",
    "    # 2) 得到 mask 与索引\n",
    "    mask = probs > threshold\n",
    "    indices = mask.nonzero(as_tuple=False)  # (K, 2)\n",
    "\n",
    "    N, C = probs.shape\n",
    "    multi_label_pred = [[] for _ in range(N)]\n",
    "\n",
    "    # 3) 阈值筛选\n",
    "    for sample_id, class_id in indices.tolist():\n",
    "        multi_label_pred[sample_id].append(class_id)\n",
    "\n",
    "    # 4) 若为空 → 选 top1\n",
    "    top1_ids = torch.argmax(probs, dim=1).tolist()\n",
    "    for i in range(N):\n",
    "        if len(multi_label_pred[i]) == 0:\n",
    "            multi_label_pred[i].append(top1_ids[i])\n",
    "\n",
    "    # 5) 根据 preds 中的真实 class_id 映射\n",
    "    final_preds = []\n",
    "    for i, idx_list in enumerate(multi_label_pred):\n",
    "        cls_list = [preds[i, idx].item() for idx in idx_list]\n",
    "        final_preds.append(cls_list)\n",
    "\n",
    "    return final_preds"
   ],
   "id": "15e936287fcee96a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:09:29.055477Z",
     "start_time": "2025-11-22T14:09:29.052934Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e162b73244799511",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:09:29.082501Z",
     "start_time": "2025-11-22T14:09:29.078847Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "19675cec91b7b24d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:09:30.961761Z",
     "start_time": "2025-11-22T14:09:29.163320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "task = 'substrate_classification'\n",
    "# task = 'tc_classification'\n",
    "if task == 'substrate_classification':\n",
    "    ckpt_path = '/home/hew/python/contp/ckpt/lightning_logs/substrate/checkpoints/last.ckpt'\n",
    "    temp_dir = './temp/inference_substrate/'\n",
    "    label_map = pd.read_csv('./data/substrate_mapping.csv')\n",
    "    select_cluster = label_map['id'].tolist()\n",
    "    label_key = 'substrate_ids'\n",
    "    dataset_name = 'TCDB_substrate'\n",
    "    dataset_path = '/home/hew/python/contp/dataset/TCDB_substrate'\n",
    "elif task == 'tc_classification':\n",
    "    ckpt_path = '/home/hew/python/contp/ckpt/lightning_logs/tc/checkpoints/last.ckpt'\n",
    "    temp_dir = './temp/inference_tc/'\n",
    "    label_map = pd.read_csv('./data/tc_mapping.csv')\n",
    "    select_cluster = label_map['id'].tolist()\n",
    "    label_key = 'label_id'\n",
    "    dataset_name = 'TCDB_tc'\n",
    "    dataset_path = '/home/hew/python/contp/dataset/TCDB_tc'\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    raise FileNotFoundError('Please download the dataset first!')\n",
    "\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "predictor = LitModelInference(ConTPModule, ConTPDataModule, ckpt_path)\n",
    "datamodule = predictor.pl_data_module\n",
    "datamodule.dataset = ProteinDataset(dataset_name, dataset_path)\n",
    "datamodule.dataframe = datamodule.dataset.metadata\n",
    "datamodule.dataset"
   ],
   "id": "20c5b275c4b81f0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[loading checkpoint]: /home/hew/python/contp/ckpt/lightning_logs/substrate/checkpoints/last.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ProteinDataset[ TCDB_substrate ], size: 47420, path: /home/hew/python/contp/dataset/TCDB_substrate"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:09:35.885640Z",
     "start_time": "2025-11-22T14:09:30.974126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "datamodule.prepare_data()\n",
    "datamodule.setup('fit')"
   ],
   "id": "e5e52cf9d7d890e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use the original split of the dataset\n",
      "[prepare_data] max_len: 2000, subset_ratio: 1, number: 41475\n",
      "============================== Setup [fit] Start ==============================\n",
      "[self.train_dataset] 28994\n",
      "[self.val_dataset] 12481\n",
      "============================== Setup [fit] End ==============================\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:09:35.923903Z",
     "start_time": "2025-11-22T14:09:35.921519Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d9a6da6698a82213",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:09:36.039149Z",
     "start_time": "2025-11-22T14:09:36.000476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cache_file = f'{temp_dir}/class_embeddings.pth'\n",
    "if os.path.exists(cache_file):\n",
    "    # if False:\n",
    "    class_embeddings = torch.load(cache_file)\n",
    "    idx2sample = pd.read_csv(f'{temp_dir}/idx2sample.csv')\n",
    "    idx2sample.set_index('sample_id', inplace=True)\n",
    "    select_cluster = datamodule.contrastive_dataset.unique_labels\n",
    "else:\n",
    "    # extract esm embeddings for all samples and group by class\n",
    "    unique_labels = datamodule.contrastive_dataset.unique_labels\n",
    "    class_embeddings_dict = {}\n",
    "    class_sequences_dict = {}\n",
    "    all_samples = []\n",
    "    for label in tqdm(unique_labels):\n",
    "        class_samples = datamodule.contrastive_dataset.label2idx[label]\n",
    "        class_embeddings = np.array(\n",
    "            [datamodule.contrastive_dataset.dataset[idx]['esm_embedding'] for idx in class_samples])\n",
    "        class_sequences = np.array([datamodule.contrastive_dataset.dataset[idx]['sequence'] for idx in class_samples])\n",
    "        class_embeddings_dict[label] = class_embeddings\n",
    "        class_sequences_dict[label] = class_sequences\n",
    "        print(label, len(class_samples), class_embeddings.shape)\n",
    "        all_samples.extend(class_samples)\n",
    "\n",
    "    temp_file = f'{temp_dir}/train_esm_embeddings.npy'\n",
    "    np.save(temp_file, class_embeddings_dict)\n",
    "\n",
    "    # record the sample mapping\n",
    "    idx2sample = {i: x for i, x in enumerate(all_samples)}\n",
    "    idx2sample = pd.DataFrame(idx2sample, index=['sample_id']).T\n",
    "    idx2sample['idx'] = idx2sample.index\n",
    "    idx2sample = idx2sample.set_index('sample_id')\n",
    "    idx2sample.to_csv(f'{temp_dir}/idx2sample.csv')\n",
    "\n",
    "    # compute the class embedding\n",
    "    concat_embed, cluster_labels = predictor.ckpt_model.model.compute_cluster_center(temp_file,\n",
    "                                                                                     return_sample_embed=True)\n",
    "\n",
    "    # compute the latent embedding for each class\n",
    "    class_embeddings = []\n",
    "    select_cluster = unique_labels\n",
    "    for i in select_cluster:\n",
    "        indices = np.where(cluster_labels == i)[0]\n",
    "        class_embeddings.append(concat_embed[indices].mean(0))\n",
    "\n",
    "    class_embeddings = torch.stack(class_embeddings, dim=0)\n",
    "    torch.save(class_embeddings, cache_file)\n",
    "\n",
    "class_embeddings.shape, class_embeddings.device"
   ],
   "id": "fca0eea18051fabd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3985882/294830964.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  class_embeddings = torch.load(cache_file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([70, 320]), device(type='cuda', index=0))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:09:36.079403Z",
     "start_time": "2025-11-22T14:09:36.074999Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "dc522ad2a6c099d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:09:36.149022Z",
     "start_time": "2025-11-22T14:09:36.146387Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "de3fcc18b4e40e17",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:09:36.663424Z",
     "start_time": "2025-11-22T14:09:36.207682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "datamodule.setup('test')\n",
    "test_dataset = datamodule.test_dataset\n",
    "test_dataset_size = len(test_dataset)\n",
    "test_dataset"
   ],
   "id": "2ff498a1746d8bc4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== Setup [test] Start ==============================\n",
      "[self.test_dataset] 12481\n",
      "============================== Setup [test] End ==============================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ProteinDataset[ test_dataset ], size: 12481, path: /home/hew/python/contp/dataset/TCDB_substrate"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:09:51.359532Z",
     "start_time": "2025-11-22T14:09:36.685847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_esm_embedding = []\n",
    "query_label = []\n",
    "for i in tqdm(range(test_dataset_size)):\n",
    "    esm_embedding = test_dataset[i]['esm_embedding']\n",
    "    query_esm_embedding.append(torch.from_numpy(esm_embedding).float())\n",
    "\n",
    "test_X = torch.stack(query_esm_embedding, dim=0)\n",
    "if task == 'substrate_classification':\n",
    "    test_y = [eval(test_dataset[s][label_key]) for s in range(test_dataset_size)]\n",
    "elif task == 'tc_classification':\n",
    "    test_y = [test_dataset[s][label_key] for s in range(test_dataset_size)]\n",
    "    test_y = [[y] for y in test_y]\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "test_X.shape, len(test_y), test_y[:5]"
   ],
   "id": "67a38ad114ffdb1d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/12481 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "02fb940a056c4f07b56d9e9c36d1f039"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([12481, 1280]), 12481, [[26], [24, 31, 25, 26], [25], [25], [25]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:09:51.670657Z",
     "start_time": "2025-11-22T14:09:51.400830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = 'cuda:0'\n",
    "test_X = predictor.ckpt_model.model.forward(test_X.to(device))\n",
    "test_X.shape"
   ],
   "id": "36b13d7d49b4163a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12481, 320])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:09:53.156652Z",
     "start_time": "2025-11-22T14:09:51.699978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_X = test_X\n",
    "query_label = test_y\n",
    "\n",
    "train_C = class_embeddings\n",
    "raw_pred, dist = predictor.ckpt_model.model.find_nearest_cluster(query_X, train_C, return_dist=True)\n",
    "pred = np.array([select_cluster[i] for i in raw_pred])\n",
    "pred = [[y] for y in pred]\n",
    "compute_label_metrics(pred, query_label)"
   ],
   "id": "2e4e01f6e4f6833d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weighted_precision': 0.9459579987307455,\n",
       " 'weighted_recall': 0.6680472029955747,\n",
       " 'weighted_f1': 0.7585857244117813,\n",
       " 'samples_precision': 0.9434340197099591,\n",
       " 'samples_recall': 0.8077317089074961,\n",
       " 'samples_f1': 0.8451752059956531,\n",
       " 'samples_acc': 0.7134844964345806,\n",
       " 'micro_precision': 0.9434340197099591,\n",
       " 'micro_recall': 0.6680472029955747,\n",
       " 'micro_f1': 0.7822101172484804,\n",
       " 'micro_acc': 0.9924948779287374}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:09:54.006667Z",
     "start_time": "2025-11-22T14:09:53.211095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if task == 'substrate_classification':\n",
    "    threshold = 0.034  # determined in the training set\n",
    "    final_preds = multi_label_from_distance(dist, threshold=threshold)\n",
    "    metrics = compute_label_metrics(final_preds, query_label)\n",
    "else:\n",
    "    final_preds = pred\n",
    "    metrics = compute_label_metrics(pred, query_label)\n",
    "metrics"
   ],
   "id": "39c675712523fbeb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weighted_precision': 0.9449007805223315,\n",
       " 'weighted_recall': 0.6948258254850789,\n",
       " 'weighted_f1': 0.7773231873093615,\n",
       " 'samples_precision': 0.9416045722832039,\n",
       " 'samples_recall': 0.8211788151756905,\n",
       " 'samples_f1': 0.8538390416925791,\n",
       " 'samples_acc': 0.7315118980850893,\n",
       " 'micro_precision': 0.9419320104599292,\n",
       " 'micro_recall': 0.6948258254850789,\n",
       " 'micro_f1': 0.7997257411518872,\n",
       " 'micro_acc': 0.9929790424302082}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:09:54.350993Z",
     "start_time": "2025-11-22T14:09:54.056326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if task == 'substrate_classification':\n",
    "    key = 'substrate'\n",
    "elif task == 'tc_classification':\n",
    "    key = 'tcid'\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "final_pred = []\n",
    "for pred_list in final_preds:\n",
    "    pred_labels = [label_map.loc[pred_y, key] for pred_y in pred_list]\n",
    "    final_pred.append(pred_labels)\n",
    "pred_df = pd.DataFrame(final_pred)\n",
    "pred_df"
   ],
   "id": "2d74250f914d87fc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                             0     1     2\n",
       "0               cation:calcium  None  None\n",
       "1               cation:lithium  None  None\n",
       "2             cation:potassium  None  None\n",
       "3             cation:potassium  None  None\n",
       "4             cation:potassium  None  None\n",
       "...                        ...   ...   ...\n",
       "12476            cation:proton  None  None\n",
       "12477  nucleic acid:nucleotide  None  None\n",
       "12478              cation:iron  None  None\n",
       "12479          anion:aspartate  None  None\n",
       "12480          anion:phosphate  None  None\n",
       "\n",
       "[12481 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cation:calcium</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cation:lithium</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cation:potassium</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cation:potassium</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cation:potassium</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12476</th>\n",
       "      <td>cation:proton</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12477</th>\n",
       "      <td>nucleic acid:nucleotide</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12478</th>\n",
       "      <td>cation:iron</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12479</th>\n",
       "      <td>anion:aspartate</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12480</th>\n",
       "      <td>anion:phosphate</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12481 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:09:54.442080Z",
     "start_time": "2025-11-22T14:09:54.439362Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a7acaf59e08191fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:09:54.511345Z",
     "start_time": "2025-11-22T14:09:54.508945Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d35cf40c87d11f71",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:09:54.591205Z",
     "start_time": "2025-11-22T14:09:54.588650Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "99059224195f5170",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:contp]",
   "language": "python",
   "name": "conda-env-contp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
